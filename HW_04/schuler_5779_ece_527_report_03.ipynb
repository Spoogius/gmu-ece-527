{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aaac6a8-4fce-4d78-8d78-3dcbf061b0f2",
   "metadata": {},
   "source": [
    "# GMU ECE 527 - Computer Exercise #4 - Report\n",
    "**Stewart Schuler - G01395779**\\\n",
    "**20240926**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce8b1d4-a31a-40a6-b435-f5ec0deaee16",
   "metadata": {},
   "source": [
    "## Exercise 4.1\n",
    "\n",
    "To aid in choosing which features to include in the linear regressor we can compute the correctlation of each feature with our $y$ variable *mpg*. *Table 1* contains the correlation results, it can be seen that *weight* and *displacement* have the highest linear correlation levels with *mpg*.\n",
    "\n",
    "|       |     mpg | cylinders | displacement | horsepower |   weight | acceleration|  model year  |  origin  |\n",
    "| ------- | ------- | ------- | ------- | ------- | ------- | ------- | ------- | ------- |\n",
    "|mpg      | 1.000000|  -0.775396 |    -0.804203 |  -0.780255| -0.831741 |  0.420289  |  0.579267  |0.563450 \n",
    "**Table 1.** Feature Correlation to mpg\n",
    "\n",
    "Another was to visualize the correlation is to plot the correlation between all features. As seen in *Figure 1*, *cylinders*, *displacement*, *horsepower*, and *weight* all have a high correlation to *mpg* (and as a result with one another). While the remaining features have a much weaker correlation to *mpg*, and likewise have almost no correlation between themselves.\n",
    "\n",
    "![Experiment 4.1 heatmap](figures/4_1_corr_heatmap.jpg)\\\n",
    "**Figure 1.** Correlation Heatmap\n",
    "\n",
    "#### 4.1.3 Questions\n",
    "**Question:** Based on what you have been able to learn about the data set, what features seem to be the best for predicting gas mileage?\n",
    "\n",
    "**Answer:** The best way to predict quality of the linear regressor is the correlation values shown in *table 1*. From the table the best single feature would be *weight*, followed closely by *displacement*. \n",
    "\n",
    "**Question:** Are there any features that seem to be irrelevant or not useful in predicting gas mileage? Whcioh ones are they and why would the not be useful?\n",
    "\n",
    "**Answer:** *Origin*, that is manufacturer country has the lowest correlation to *mpg*. That can be seen when plotting it vs *mpg*. Of the three possible discrete values there is significant overlap. And while they do trend upward with enumerated *origin* there is still significant overlap. A case could be made that these could correlate with underlaying country emission laws, but that is a far weaker predicter than other dataset features. *Model year* likewise has a very slight correlation with *mpg* with a lot of overlap between feature values. Again this may not be entirly useless because we could reasonably make the assumption that as model year increases average *mpg* should also increase because that is desirable for manufacturers, but alone that *model year* feature doesn't take into account the type of vehicle, when used alone we could comparing a small commuter vehicle to a semi-truck and have now was to distinguish between without additional features.   \n",
    "\n",
    "![Experiment 4.1.3 features](figures/4_1_3_features.jpg)\\\n",
    "**Figure 2.** *mpg* vs *features*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc1c79b-1724-4f4d-8853-1277224d109c",
   "metadata": {},
   "source": [
    "## 4.1.4\n",
    "\n",
    "Next we choose a specific single feature to run regression on to make a predictor for *mpg*. As dicussed in the previous section *weight* was chosen as the single feature.\\\n",
    "\n",
    "#### 4.1.4 Questions\n",
    "**Question:** Is it important or necessary to scale the data before performing regression?\n",
    "\n",
    "**Answer:** Unlike the SGD algorithms previous studied the linear regression algorithm being used here does not require feature scaling. The is because we are finding the closed form solution to the problem. With the SGD algorithms we were estimating a value then updating by some step size based on the previous result. That step size update is highly dependent on data scaling. Since there is no step size for linear regression the algorithm performs the same independent of scaling.\n",
    "\n",
    "#### 4.1.4 Exercise\n",
    "\n",
    "Using *weight* as the only feature we produced the regressor shown in *Figure 3* with residual plot shown in *Figure 4*. As can be clearly seen from the residuals plot, as the *mpg* value increases the model becomes less accurate, by under predicting the value. From this it can be concluded that a linear model doesn't fit this dataset well, given that we expect *weight* to be the best performing linearly modeled feature. From the residual it can be seen that a predictor with a polynomial like curve would reduce the residual error to the desired gausian distribution around 0.\n",
    "\n",
    "![Experiment 4.1.4 weight data](figures/4_1_4_weight_data.jpg)\\\n",
    "**Figure 3.** *mpg* vs *weight*\n",
    "\n",
    "![Experiment 4.1.4 weight residual](figures/4_1_4_weight_residual.jpg)\\\n",
    "**Figure 4.** *weight* Regressor Residual\n",
    "\n",
    "The experiment was linear regression was repeated using the expected second best performing feature *displacement*. This too sufferse from under predicting as *mpg* increases. However the similarity between the results of the two features confirms what the correlation values predicted. That since the two feature sets are highly correlated their results should be as well. The $R^{2}$ score and mse for both predictors can be found in Table 2, included in that table is the results of a regressor using the *origin* feature. It's inclusion demonstrates that the linear correlation table is a good predictor of performance for the linear regression model. \n",
    "\n",
    "![Experiment 4.1.4 displacement data](figures/4_1_4_displacement_data.jpg)\\\n",
    "**Figure 5.** *mpg* vs *displacement*\n",
    "\n",
    "![Experiment 4.1.4 displacement residual](figures/4_1_4_displacement_residual.jpg)\\\n",
    "**Figure 6.** *displacement* Regressor Residual\n",
    "\n",
    "\n",
    "| feature  | $R^{2}$ Score | MSE |    \n",
    "| ------- | ------- | ------- | \n",
    "|  weight | 0.671 |  18.503 | \n",
    "|  displacement | 0.637 |  17.532 | \n",
    "|  both | 0.726 |  15.511 |\n",
    "| all | 0.772 | 10.944 |\n",
    "|  origin | 0.308 | 34.617 |\n",
    "**Table 2.** Regressor Performance\n",
    "\n",
    "\n",
    "We consider next multi-variable regression. For the two variable regressor we combined weight and displacement. *Figure 7* shows the regressor model in each feature space. The two variable regressor produced scores shown in the *both* row of *Table 2*. As expected it out performs both of the individual parts, since each feature represents some information not captured by the other, but relevant to *mpg*. \n",
    "\n",
    "![Experiment 4.1.4 both data](figures/4_1_4_both_data.jpg)\\\n",
    "**Figure 7.** *mpg* vs *displacement* & *weight*\n",
    "\n",
    "The final linear regressor tested on this data set considers *all* available features. The score results are in the *all* row of *Table 2*. This model performs the best of all the models tested so far. However it only marginally out performs the two feature model. This is because some of the additional included features have lesser correlation to *mpg* and likely don't contain useful information. Where as some of the newly include features like *horse power* and *cylinders* are decently correlated to *mpg* and will slightly improve the prediction. \n",
    "\n",
    "However it should be noted that because the dataset is rather small, there is a good sized variance between experimentally measured score values depending on the random seed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
